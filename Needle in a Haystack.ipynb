{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HmhpszG53HB",
        "outputId": "609cf00b-fb05-4352-b948-6163161aba28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['noncomplaint.txt', 'complaint.txt', 'customertweets.csv', 'final(1).ipynb']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "#import os\n",
        "#path = \"/content/gdrive/MyDrive/noncomplaint_detect\"\n",
        "\n",
        "#os.chdir(path)\n",
        "#os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-jVoj8H532y",
        "outputId": "845fbe32-c21b-4f21-e45d-9600b86f5c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Dropout, TextVectorization, Bidirectional, LSTM, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KsRrXz9a69ud",
        "outputId": "608faea8-42a0-4f85-a63b-4857f0321887"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-07 20:48:19.617449: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-03-07 20:48:19.617504: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xhx4p5yk7AoM"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "max_sequence_length = 600\n",
        "vocab_size = 100000\n",
        "max_num_word = 1000000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UUYGX3x-7Chl"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-68mBm5z7EWR"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.read().split('\\n')\n",
        "    cleaned_lines = [clean_text(line) for line in lines if line]\n",
        "    return cleaned_lines\n",
        "\n",
        "\n",
        "complaints_data = load_and_preprocess_data('/Users/emmali/Downloads/complaint.txt')\n",
        "non_complaints_data = load_and_preprocess_data('/Users/emmali/Downloads/noncomplaint.txt')\n",
        "\n",
        "complaints_data = file.read('/Users/emmali/Downloads/complaint.txt')\n",
        "non_complaints_data = file.read('/Users/emmali/Downloads/noncomplaint.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ymlTF5hi7GE4"
      },
      "outputs": [],
      "source": [
        "texts = complaints_data + non_complaints_data\n",
        "labels = [0] * len(complaints_data) + [1] * len(non_complaints_data)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xlWqJbfA7IZL"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=max_num_word)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
        "X_test = pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tYuoB-Mb7Kwi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-07 20:13:55.019039: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-03-07 20:13:55.019063: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "X_train = tf.convert_to_tensor(X_train)\n",
        "y_train = tf.convert_to_tensor(y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y4G40Aop7Mah"
      },
      "outputs": [],
      "source": [
        "#new\n",
        "X_test = tf.convert_to_tensor(X_test)\n",
        "y_test = tf.convert_to_tensor(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L2p796717N3C"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, input_length):\n",
        "    inputs = Input(shape=(input_length,))\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length)(inputs)\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(16))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yySw10bf7Pmf",
        "outputId": "6773c7f8-7b9e-42da-837f-c7fb499a117b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-07 20:07:44.303581: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 58s 176ms/step - loss: 0.4326 - accuracy: 0.8086 - val_loss: 0.3332 - val_accuracy: 0.8617\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/emmali/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 52s 167ms/step - loss: 0.2753 - accuracy: 0.8941 - val_loss: 0.3259 - val_accuracy: 0.8705\n",
            "Epoch 3/20\n",
            "312/312 [==============================] - 51s 165ms/step - loss: 0.2177 - accuracy: 0.9180 - val_loss: 0.3323 - val_accuracy: 0.8657\n",
            "Epoch 4/20\n",
            "312/312 [==============================] - 52s 168ms/step - loss: 0.1809 - accuracy: 0.9342 - val_loss: 0.3703 - val_accuracy: 0.8585\n",
            "Epoch 5/20\n",
            "312/312 [==============================] - 56s 179ms/step - loss: 0.1534 - accuracy: 0.9434 - val_loss: 0.3621 - val_accuracy: 0.8581\n",
            "98/98 [==============================] - 5s 55ms/step - loss: 0.4219 - accuracy: 0.8380\n",
            "Test Accuracy: 0.838\n"
          ]
        }
      ],
      "source": [
        "model_1 = build_model(vocab_size, 256, max_sequence_length)\n",
        "model_1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('model_checkpoint_path.h5', save_best_only=True),\n",
        "    EarlyStopping(monitor='val_loss', patience=3)\n",
        "]\n",
        "\n",
        "model_1.fit(X_train, y_train, batch_size=batch_size, epochs=20, validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "test_loss, test_acc = model_1.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3nQDEoUG7Rvx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-07 20:14:00.538436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divide the data set into training set, validation set and test set\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Create a TextVectorization instance and fit it to the training set to build the vocabulary\n",
        "max_tokens = vocab_size\n",
        "output_mode = 'int'\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_tokens,output_sequence_length=max_sequence_length, output_mode=output_mode)\n",
        "text_vectorizer.adapt(X_train)\n",
        "\n",
        "# Define a function to vectorize text and labels\n",
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return text_vectorizer(text), label\n",
        "\n",
        "# Use tf.data.Dataset.from_tensor_slices to divide the data set into batches, and call the vectorize_text function through the map function to vectorize the text\n",
        "batch_size = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n",
        "train_dataset = train_dataset.map(vectorize_text)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)\n",
        "val_dataset = val_dataset.map(vectorize_text)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)\n",
        "test_dataset = test_dataset.map(vectorize_text)\n",
        "\n",
        "# Process the data set to improve the efficiency of data loading\n",
        "train_ds = train_dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_dataset.cache().prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vnOGIIb77UTP"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input( shape=(None,), dtype=\"int64\" )\n",
        "d_emb = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejoDeIuy7ZTc",
        "outputId": "d455c2a2-7f53-459c-a504-8ec2e50ab290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         25600000  \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, None, 64)          73984     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 32)                10368     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25684385 (97.98 MB)\n",
            "Trainable params: 25684385 (97.98 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedded = Embedding( input_dim=vocab_size, output_dim=d_emb )(inputs)\n",
        "x = Bidirectional(LSTM(32, return_sequences=True))(embedded)\n",
        "x = Bidirectional(LSTM(16))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "model_rnn = keras.Model(inputs, outputs)\n",
        "model_rnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEat08Z37b0F",
        "outputId": "fbe27dc0-05c6-48c4-de5d-56eea54e1e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "390/390 [==============================] - 68s 168ms/step - loss: 0.4203 - accuracy: 0.8165 - val_loss: 0.3695 - val_accuracy: 0.8332\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 61s 158ms/step - loss: 0.2867 - accuracy: 0.8866 - val_loss: 0.3592 - val_accuracy: 0.8467\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 61s 157ms/step - loss: 0.2426 - accuracy: 0.9061 - val_loss: 0.3676 - val_accuracy: 0.8448\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 61s 156ms/step - loss: 0.2069 - accuracy: 0.9231 - val_loss: 0.3756 - val_accuracy: 0.8352\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 61s 155ms/step - loss: 0.1784 - accuracy: 0.9363 - val_loss: 0.4147 - val_accuracy: 0.8319\n",
            "49/49 [==============================] - 2s 50ms/step - loss: 0.3921 - accuracy: 0.8409\n",
            "Test acc: 0.841\n"
          ]
        }
      ],
      "source": [
        "model_rnn.compile( optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"] )\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"/Users/emmali/Downloads/models/complaints_embeddings_bidir_gru.keras\", save_best_only=True),\n",
        "    EarlyStopping(monitor='val_loss', patience=3)\n",
        "]\n",
        "model_rnn.fit( train_ds, validation_data=val_ds, epochs=20, callbacks = callbacks )\n",
        "print(f\"Test acc: {model_rnn.evaluate(test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "li6UpW2c7i-q",
        "outputId": "8ae1cd34-5487-4155-d4db-18da4d0512f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>My 8:50 flight to Dallas has been delayed to 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>@suzij77 @united @jimjefferies @Delta Oh that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>@ArianFoster I hate @united 2. They didn't let...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>I'm so upset with @AmericanAir They changed my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Slightly delayed flight home from Philly. but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157205</th>\n",
              "      <td>173658</td>\n",
              "      <td>@DeltaAssist havoc at gate . Flight prior dela...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157206</th>\n",
              "      <td>173659</td>\n",
              "      <td>@united flight got cancelled. baggage is missi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157207</th>\n",
              "      <td>173660</td>\n",
              "      <td>@Jetblue I've been on hold 36 minutes. My flig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157208</th>\n",
              "      <td>173661</td>\n",
              "      <td>Hey @United 60 min wait on customer service li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157209</th>\n",
              "      <td>173662</td>\n",
              "      <td>@AmericanAir another week another missing flig...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157210 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                              tweet\n",
              "0            6  My 8:50 flight to Dallas has been delayed to 1...\n",
              "1            7  @suzij77 @united @jimjefferies @Delta Oh that ...\n",
              "2            8  @ArianFoster I hate @united 2. They didn't let...\n",
              "3            9  I'm so upset with @AmericanAir They changed my...\n",
              "4           10  Slightly delayed flight home from Philly. but ...\n",
              "...        ...                                                ...\n",
              "157205  173658  @DeltaAssist havoc at gate . Flight prior dela...\n",
              "157206  173659  @united flight got cancelled. baggage is missi...\n",
              "157207  173660  @Jetblue I've been on hold 36 minutes. My flig...\n",
              "157208  173661  Hey @United 60 min wait on customer service li...\n",
              "157209  173662  @AmericanAir another week another missing flig...\n",
              "\n",
              "[157210 rows x 2 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "column_names = ['id', 'tweet']\n",
        "df = pd.read_csv('/Users/emmali/Desktop/Simon/2024 Spring A/AI and Deep Learning (CIS433.31A.SPRINGA2024SIMON) CIS433.31A.SPRINGA2024SIMON/Final/customertweets.csv', header=None, names=column_names)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QTqoV-mp7k8C",
        "outputId": "87b926b7-5475-40ad-f1b6-53e518c86725"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>My 8:50 flight to Dallas has been delayed to 1...</td>\n",
              "      <td>My 8:50 flight to Dallas has been delayed to 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>@suzij77 @united @jimjefferies @Delta Oh that ...</td>\n",
              "      <td>Oh that sucks. Deep breath though. don't take ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>@ArianFoster I hate @united 2. They didn't let...</td>\n",
              "      <td>I hate 2. They didn't let me on my flight 2 we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>I'm so upset with @AmericanAir They changed my...</td>\n",
              "      <td>I'm so upset with They changed my boyfriends f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Slightly delayed flight home from Philly. but ...</td>\n",
              "      <td>Slightly delayed flight home from Philly. but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157205</th>\n",
              "      <td>173658</td>\n",
              "      <td>@DeltaAssist havoc at gate . Flight prior dela...</td>\n",
              "      <td>havoc at gate . Flight prior delayed . our fli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157206</th>\n",
              "      <td>173659</td>\n",
              "      <td>@united flight got cancelled. baggage is missi...</td>\n",
              "      <td>flight got cancelled. baggage is missing and y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157207</th>\n",
              "      <td>173660</td>\n",
              "      <td>@Jetblue I've been on hold 36 minutes. My flig...</td>\n",
              "      <td>I've been on hold 36 minutes. My flight was ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157208</th>\n",
              "      <td>173661</td>\n",
              "      <td>Hey @United 60 min wait on customer service li...</td>\n",
              "      <td>Hey 60 min wait on customer service line. Any ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157209</th>\n",
              "      <td>173662</td>\n",
              "      <td>@AmericanAir another week another missing flig...</td>\n",
              "      <td>another week another missing flight crew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157210 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                              tweet  \\\n",
              "0            6  My 8:50 flight to Dallas has been delayed to 1...   \n",
              "1            7  @suzij77 @united @jimjefferies @Delta Oh that ...   \n",
              "2            8  @ArianFoster I hate @united 2. They didn't let...   \n",
              "3            9  I'm so upset with @AmericanAir They changed my...   \n",
              "4           10  Slightly delayed flight home from Philly. but ...   \n",
              "...        ...                                                ...   \n",
              "157205  173658  @DeltaAssist havoc at gate . Flight prior dela...   \n",
              "157206  173659  @united flight got cancelled. baggage is missi...   \n",
              "157207  173660  @Jetblue I've been on hold 36 minutes. My flig...   \n",
              "157208  173661  Hey @United 60 min wait on customer service li...   \n",
              "157209  173662  @AmericanAir another week another missing flig...   \n",
              "\n",
              "                                            cleaned_tweet  \n",
              "0       My 8:50 flight to Dallas has been delayed to 1...  \n",
              "1       Oh that sucks. Deep breath though. don't take ...  \n",
              "2       I hate 2. They didn't let me on my flight 2 we...  \n",
              "3       I'm so upset with They changed my boyfriends f...  \n",
              "4       Slightly delayed flight home from Philly. but ...  \n",
              "...                                                   ...  \n",
              "157205  havoc at gate . Flight prior delayed . our fli...  \n",
              "157206  flight got cancelled. baggage is missing and y...  \n",
              "157207  I've been on hold 36 minutes. My flight was ca...  \n",
              "157208  Hey 60 min wait on customer service line. Any ...  \n",
              "157209        another week another missing flight crew...  \n",
              "\n",
              "[157210 rows x 3 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['cleaned_tweet'] = df['tweet'].apply(clean_text)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbMv7oNI7m_O",
        "outputId": "3139629f-00b5-43b5-eb0e-3a677ef968fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157210/157210 [46:04<00:00, 56.86it/s]   \n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def vectorize_text(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return text_vectorizer(text)\n",
        "\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "df['vectorized_tweet'] = df['cleaned_tweet'].progress_apply(vectorize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akOsSMO9I5G2",
        "outputId": "e3cb509a-75ad-4a5d-d8bd-edbeb7c0e1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4913/4913 [==============================] - 261s 53ms/step\n"
          ]
        }
      ],
      "source": [
        "vectorized_tweets = df['vectorized_tweet'].apply(lambda x: x[0])\n",
        "\n",
        "predictions = model_rnn.predict(np.array(vectorized_tweets.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Nf5xQI6ZJIUV",
        "outputId": "31e358a2-d0ae-44e1-d711-20002614c940"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "      <th>vectorized_tweet</th>\n",
              "      <th>prediction_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46770</th>\n",
              "      <td>52299</td>\n",
              "      <td>@JetBlue Can't thank your customer service tea...</td>\n",
              "      <td>Can't thank your customer service team enough....</td>\n",
              "      <td>((tf.Tensor(17, shape=(), dtype=int64), tf.Ten...</td>\n",
              "      <td>0.996903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112478</th>\n",
              "      <td>124681</td>\n",
              "      <td>#JetBlue ShoutOUT 2 @JetBlue Boston Crew hated...</td>\n",
              "      <td>ShoutOUT 2 Boston Crew hated to leave Florida....</td>\n",
              "      <td>((tf.Tensor(613, shape=(), dtype=int64), tf.Te...</td>\n",
              "      <td>0.996877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125665</th>\n",
              "      <td>139200</td>\n",
              "      <td>thank you @JetBlue for an amazing experience. ...</td>\n",
              "      <td>thank you for an amazing experience. flight al...</td>\n",
              "      <td>((tf.Tensor(125, shape=(), dtype=int64), tf.Te...</td>\n",
              "      <td>0.996705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31053</th>\n",
              "      <td>34653</td>\n",
              "      <td>can't wait until this video leaks (it's going ...</td>\n",
              "      <td>can't wait until this video leaks (it's going ...</td>\n",
              "      <td>((tf.Tensor(17, shape=(), dtype=int64), tf.Ten...</td>\n",
              "      <td>0.996572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126950</th>\n",
              "      <td>140624</td>\n",
              "      <td>@radiodrew @SouthwestAir Heading there after w...</td>\n",
              "      <td>Heading there after work today!!! Can't wait! ...</td>\n",
              "      <td>((tf.Tensor(660, shape=(), dtype=int64), tf.Te...</td>\n",
              "      <td>0.996559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127329</th>\n",
              "      <td>141028</td>\n",
              "      <td>@airlinewriter @AlaskaAir Don't buy the \"fell ...</td>\n",
              "      <td>Don't buy the \"fell asleep\" claim--just the ca...</td>\n",
              "      <td>((tf.Tensor(87, shape=(), dtype=int64), tf.Ten...</td>\n",
              "      <td>0.500119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98898</th>\n",
              "      <td>109673</td>\n",
              "      <td>No. this isn't FRA it's IAD. my flt 1st was cx...</td>\n",
              "      <td>No. this isn't FRA it's IAD. my flt 1st was cx...</td>\n",
              "      <td>((tf.Tensor(24, shape=(), dtype=int64), tf.Ten...</td>\n",
              "      <td>0.500082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34646</th>\n",
              "      <td>38705</td>\n",
              "      <td>@SouthwestAir tring to change internationa iti...</td>\n",
              "      <td>tring to change internationa itinareray usa to...</td>\n",
              "      <td>((tf.Tensor(1, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>0.500052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115451</th>\n",
              "      <td>127948</td>\n",
              "      <td>I will NEVER fly @AmericanAir again if I get t...</td>\n",
              "      <td>I will NEVER fly again if I get to make the ch...</td>\n",
              "      <td>((tf.Tensor(4, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>0.500042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133734</th>\n",
              "      <td>148007</td>\n",
              "      <td>@SouthwestAir how do I get that job? Your new ...</td>\n",
              "      <td>how do I get that job? Your new slogan - we re...</td>\n",
              "      <td>((tf.Tensor(67, shape=(), dtype=int64), tf.Ten...</td>\n",
              "      <td>0.500027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31385 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                              tweet  \\\n",
              "46770    52299  @JetBlue Can't thank your customer service tea...   \n",
              "112478  124681  #JetBlue ShoutOUT 2 @JetBlue Boston Crew hated...   \n",
              "125665  139200  thank you @JetBlue for an amazing experience. ...   \n",
              "31053    34653  can't wait until this video leaks (it's going ...   \n",
              "126950  140624  @radiodrew @SouthwestAir Heading there after w...   \n",
              "...        ...                                                ...   \n",
              "127329  141028  @airlinewriter @AlaskaAir Don't buy the \"fell ...   \n",
              "98898   109673  No. this isn't FRA it's IAD. my flt 1st was cx...   \n",
              "34646    38705  @SouthwestAir tring to change internationa iti...   \n",
              "115451  127948  I will NEVER fly @AmericanAir again if I get t...   \n",
              "133734  148007  @SouthwestAir how do I get that job? Your new ...   \n",
              "\n",
              "                                            cleaned_tweet  \\\n",
              "46770   Can't thank your customer service team enough....   \n",
              "112478  ShoutOUT 2 Boston Crew hated to leave Florida....   \n",
              "125665  thank you for an amazing experience. flight al...   \n",
              "31053   can't wait until this video leaks (it's going ...   \n",
              "126950  Heading there after work today!!! Can't wait! ...   \n",
              "...                                                   ...   \n",
              "127329  Don't buy the \"fell asleep\" claim--just the ca...   \n",
              "98898   No. this isn't FRA it's IAD. my flt 1st was cx...   \n",
              "34646   tring to change internationa itinareray usa to...   \n",
              "115451  I will NEVER fly again if I get to make the ch...   \n",
              "133734  how do I get that job? Your new slogan - we re...   \n",
              "\n",
              "                                         vectorized_tweet  prediction_prob  \n",
              "46770   ((tf.Tensor(17, shape=(), dtype=int64), tf.Ten...         0.996903  \n",
              "112478  ((tf.Tensor(613, shape=(), dtype=int64), tf.Te...         0.996877  \n",
              "125665  ((tf.Tensor(125, shape=(), dtype=int64), tf.Te...         0.996705  \n",
              "31053   ((tf.Tensor(17, shape=(), dtype=int64), tf.Ten...         0.996572  \n",
              "126950  ((tf.Tensor(660, shape=(), dtype=int64), tf.Te...         0.996559  \n",
              "...                                                   ...              ...  \n",
              "127329  ((tf.Tensor(87, shape=(), dtype=int64), tf.Ten...         0.500119  \n",
              "98898   ((tf.Tensor(24, shape=(), dtype=int64), tf.Ten...         0.500082  \n",
              "34646   ((tf.Tensor(1, shape=(), dtype=int64), tf.Tens...         0.500052  \n",
              "115451  ((tf.Tensor(4, shape=(), dtype=int64), tf.Tens...         0.500042  \n",
              "133734  ((tf.Tensor(67, shape=(), dtype=int64), tf.Ten...         0.500027  \n",
              "\n",
              "[31385 rows x 5 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['prediction_prob'] = predictions\n",
        "df_sorted = df[df['prediction_prob']>0.5].sort_values('prediction_prob', ascending=False)\n",
        "df_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gWTudK0lJPWK"
      },
      "outputs": [],
      "source": [
        "df_sorted[['id','tweet']].to_csv('/Users/emmali/Downloads/non_complaint_tweets_sorted.csv',index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2FrDep6NGDp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
